# å®Œæ•´å®‰è£…é…ç½®æŒ‡å—

æœ¬æ–‡æ¡£æä¾›è¯¦ç»†çš„ç¯å¢ƒé…ç½®å’Œæ•…éšœæ’é™¤æŒ‡å—ï¼Œç¡®ä¿é¡¹ç›®èƒ½å¤Ÿæ­£å¸¸è¿è¡Œã€‚

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **CPU**: Intel Core Ultra å¤„ç†å™¨ï¼ˆæ¨èï¼‰æˆ–å…¶ä»– x86-64 å¤„ç†å™¨
- **GPU**: Intel Arc 140V (16GB) æˆ–å…¶ä»– Intel Arc/Iris Xe GPU
- **NPU**: Intel AI Boostï¼ˆå¯é€‰ï¼Œç”¨äºæœ€é«˜æ€§èƒ½ï¼‰
- **å†…å­˜**: 16GB RAMï¼ˆæ¨è 32GBï¼‰
- **å­˜å‚¨**: è‡³å°‘ 50GB å¯ç”¨ç©ºé—´ï¼ˆç”¨äºæ¨¡å‹å’Œç¼“å­˜ï¼‰

### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10 (64-bit) æˆ– Windows 11
- **Python**: 3.8, 3.9, 3.10, æˆ– 3.11ï¼ˆæ¨è 3.11ï¼‰
- **Git**: ç”¨äºå…‹éš†é¡¹ç›®
- **é©±åŠ¨**: Intel GPU/NPU é©±åŠ¨ï¼ˆè§ä¸‹æ–‡ï¼‰

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### 1. å®‰è£… Python

å¦‚æœè¿˜æ²¡æœ‰å®‰è£… Pythonï¼š

1. è®¿é—® [Python å®˜ç½‘](https://www.python.org/downloads/)
2. ä¸‹è½½ Python 3.11ï¼ˆæ¨èï¼‰
3. å®‰è£…æ—¶å‹¾é€‰ "Add Python to PATH"

éªŒè¯å®‰è£…ï¼š
```cmd
python --version
pip --version
```

### 2. å®‰è£… Git

1. è®¿é—® [Git å®˜ç½‘](https://git-scm.com/download/win)
2. ä¸‹è½½å¹¶å®‰è£… Git for Windows

éªŒè¯å®‰è£…ï¼š
```cmd
git --version
```

### 3. å®‰è£… Intel GPU/NPU é©±åŠ¨

#### Intel Arc GPU é©±åŠ¨

1. è®¿é—® [Intel é©±åŠ¨ä¸‹è½½é¡µé¢](https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html)
2. ä¸‹è½½æœ€æ–°ç‰ˆæœ¬é©±åŠ¨
3. å®‰è£…å¹¶é‡å¯ç”µè„‘

#### Intel NPU é©±åŠ¨

Intel NPU é©±åŠ¨é€šå¸¸éšç³»ç»Ÿé©±åŠ¨æ›´æ–°è‡ªåŠ¨å®‰è£…ã€‚æ£€æŸ¥æ–¹æ³•ï¼š

1. æ‰“å¼€"è®¾å¤‡ç®¡ç†å™¨"
2. æŸ¥æ‰¾"ç¥ç»å¤„ç†å™¨"æˆ–"Neural Processor"
3. å¦‚æœæ²¡æœ‰ï¼Œæ›´æ–° Windows å’Œ Intel é©±åŠ¨

---

## ğŸ“¦ é¡¹ç›®å®‰è£…

### æ­¥éª¤ 1: å…‹éš†é¡¹ç›®

```cmd
# å…‹éš†é¡¹ç›®
git clone https://github.com/yangzhao917/petlingo.git

# è¿›å…¥é¡¹ç›®ç›®å½•
cd petlingo
```

### æ­¥éª¤ 2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```cmd
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
venv\Scripts\activate

# ä½ ä¼šçœ‹åˆ°å‘½ä»¤æç¤ºç¬¦å‰é¢æœ‰ (venv)
```

### æ­¥éª¤ 3: å®‰è£…ä¾èµ–

```cmd
# å‡çº§ pip
python -m pip install --upgrade pip

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt
```

**æ³¨æ„**: é¦–æ¬¡å®‰è£…å¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

### æ­¥éª¤ 4: éªŒè¯å®‰è£…

```cmd
# æ£€æŸ¥ OpenVINO
python -c "import openvino; print(f'OpenVINO version: {openvino.__version__}')"

# æ£€æŸ¥ OpenVINO GenAI
python -c "import openvino_genai; print('OpenVINO GenAI installed successfully')"

# æ£€æŸ¥å¯ç”¨è®¾å¤‡
python -c "from openvino.runtime import Core; core = Core(); print('Available devices:', core.available_devices)"
```

å¦‚æœçœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼Œè¯´æ˜å®‰è£…æˆåŠŸï¼š
```
OpenVINO version: 2025.3.0
OpenVINO GenAI installed successfully
Available devices: ['CPU', 'GPU', 'NPU']
```

---

## ğŸš€ è¿è¡Œé¡¹ç›®

### æ–¹æ¡ˆ 1: Intel Ollamaï¼ˆæœ€ç®€å•ï¼‰

#### 1.1 é¦–æ¬¡éƒ¨ç½²

```cmd
# è¿è¡Œä¸€é”®éƒ¨ç½²è„šæœ¬
setup_qwen3_auto.bat
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- é…ç½®ç¯å¢ƒå˜é‡
- å¯åŠ¨ Ollama æœåŠ¡
- ä¸‹è½½ Qwen æ¨¡å‹ï¼ˆçº¦ 18GBï¼Œéœ€è¦æ—¶é—´ï¼‰
- é…ç½®ä¼˜åŒ–å‚æ•°

#### 1.2 æ—¥å¸¸ä½¿ç”¨

```cmd
# è¿è¡Œæ¨¡å‹
run_qwen3.bat

# æˆ–æ‰‹åŠ¨è¿è¡Œ
cd ollama-intel-2.3.0b20250923-win
ollama.exe run qwen3:30b
```

### æ–¹æ¡ˆ 2: OpenVINO NPUï¼ˆæœ€é«˜æ€§èƒ½ï¼‰

#### 2.1 è‡ªåŠ¨éƒ¨ç½²

```cmd
# è¿è¡Œéƒ¨ç½²è„šæœ¬ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼‰
python deploy_qwen3_npu.py
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥ä¾èµ–
- ä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 4.7GBï¼‰
- é…ç½® NPU æ¨ç†
- è¿›å…¥äº¤äº’æ¨¡å¼

#### 2.2 æ‰‹åŠ¨éƒ¨ç½²

å¦‚æœè‡ªåŠ¨éƒ¨ç½²å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨æ“ä½œï¼š

```cmd
# 1. ä¸‹è½½æ¨¡å‹
python -c "from huggingface_hub import snapshot_download; snapshot_download('OpenVINO/qwen3-8b-int4-cw-ov', local_dir='qwen3-8b-int4-cw-ov')"

# 2. æµ‹è¯•æ¨¡å‹
python quick_test_npu.py
```

### æ–¹æ¡ˆ 3: ä»æºç å¯¼å‡ºæ¨¡å‹

å¦‚æœæƒ³ä»åŸå§‹æ¨¡å‹å¯¼å‡ºï¼š

```cmd
# å¯¼å‡º Qwen3-8B ä¸º OpenVINO INT4 æ ¼å¼
optimum-cli export openvino ^
    --model Qwen/Qwen3-8B ^
    --task text-generation-with-past ^
    --weight-format int4 ^
    --group-size 128 ^
    --ratio 0.8 ^
    Qwen3-8B-int4-ov

# è¿è¡Œå¯¼å‡ºçš„æ¨¡å‹
python -c "import openvino_genai as ov_genai; pipe = ov_genai.LLMPipeline('Qwen3-8B-int4-ov', 'NPU'); print(pipe.generate('Hello', max_length=50))"
```

---

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### å¿«é€Ÿæµ‹è¯•

```cmd
# æµ‹è¯• NPU æ¨ç†
python quick_test_npu.py

# æµ‹è¯• Qwen3-4B
python test_qwen3_4b_npu.py

# æµ‹è¯• Qwen3-8B
python test_qwen3_npu.py
```

### æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§

```cmd
# æ£€æŸ¥ OpenVINO è®¾å¤‡
python test_npu.py
```

é¢„æœŸè¾“å‡ºï¼š
```
Available devices: ['CPU', 'GPU.0', 'NPU']
```

---

## ğŸ› å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: æ¨¡å—å¯¼å…¥é”™è¯¯

**é”™è¯¯ä¿¡æ¯**:
```
ModuleNotFoundError: No module named 'openvino_genai'
```

**è§£å†³æ–¹æ¡ˆ**:
```cmd
# é‡æ–°å®‰è£… openvino-genai
pip install --upgrade openvino-genai

# æˆ–ä»æºç å®‰è£…
pip install git+https://github.com/openvinotoolkit/openvino.genai.git
```

### é—®é¢˜ 2: NPU è®¾å¤‡ä¸å¯ç”¨

**é”™è¯¯ä¿¡æ¯**:
```
Device NPU not found
```

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥è®¾å¤‡ç®¡ç†å™¨ä¸­æ˜¯å¦æœ‰"ç¥ç»å¤„ç†å™¨"
2. æ›´æ–° Intel NPU é©±åŠ¨
3. æ›´æ–° Windows åˆ°æœ€æ–°ç‰ˆæœ¬
4. ä¸´æ—¶ä½¿ç”¨ GPU æˆ– CPUï¼š
   ```python
   pipe = ov_genai.LLMPipeline(model_path, "GPU")  # æˆ– "CPU"
   ```

### é—®é¢˜ 3: æ¨¡å‹ä¸‹è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
Connection timeout / Download failed
```

**è§£å†³æ–¹æ¡ˆ**:

**æ–¹æ³• A: ä½¿ç”¨ ModelScopeï¼ˆå›½å†…æ¨èï¼‰**
```cmd
pip install modelscope
python -c "from modelscope import snapshot_download; snapshot_download('OpenVINO/Qwen3-8B-int4-cw-ov', local_dir='qwen3-8b-int4-cw-ov')"
```

**æ–¹æ³• B: é…ç½® HuggingFace é•œåƒ**
```cmd
set HF_ENDPOINT=https://hf-mirror.com
python deploy_qwen3_npu.py
```

**æ–¹æ³• C: æ‰‹åŠ¨ä¸‹è½½**
1. è®¿é—® https://www.modelscope.cn/models/OpenVINO/Qwen3-8B-int4-cw-ov
2. ç‚¹å‡»"æ–‡ä»¶"æ ‡ç­¾
3. ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ° `qwen3-8b-int4-cw-ov/` ç›®å½•

### é—®é¢˜ 4: æ˜¾å­˜ä¸è¶³ (OOM)

**é”™è¯¯ä¿¡æ¯**:
```
Out of memory / Allocation failed
```

**è§£å†³æ–¹æ¡ˆ**:

**å¯¹äº Intel Ollama**:
```cmd
# ç¼–è¾‘ setup_qwen3_auto.batï¼Œæ·»åŠ ï¼š
set OLLAMA_NUM_PARALLEL=1
set OLLAMA_NUM_CTX=4096
set OLLAMA_SET_OT=exps=CPU
```

**å¯¹äº OpenVINO**:
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python test_qwen3_4b_npu.py  # 4B è€Œé 8B

# æˆ–å‡å°‘ç”Ÿæˆé•¿åº¦
response = pipe.generate(prompt, max_length=100)  # è€Œé 200
```

### é—®é¢˜ 5: Intel Ollama æœåŠ¡å¯åŠ¨å¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
Failed to start Ollama service
```

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ç«¯å£ 11434 æ˜¯å¦è¢«å ç”¨ï¼š
   ```cmd
   netstat -ano | findstr :11434
   ```
2. å¦‚æœè¢«å ç”¨ï¼Œç»“æŸå ç”¨è¿›ç¨‹æˆ–æ›´æ”¹ç«¯å£ï¼š
   ```cmd
   set OLLAMA_HOST=0.0.0.0:11435
   ```
3. æ£€æŸ¥ Intel GPU é©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…

### é—®é¢˜ 6: Python ç‰ˆæœ¬ä¸å…¼å®¹

**é”™è¯¯ä¿¡æ¯**:
```
Python version 3.7 is not supported
```

**è§£å†³æ–¹æ¡ˆ**:
1. å®‰è£… Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
2. ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒéš”ç¦»ä¸åŒ Python ç‰ˆæœ¬

### é—®é¢˜ 7: é¦–æ¬¡è¿è¡Œå¾ˆæ…¢

**ç°è±¡**: æ¨¡å‹åŠ è½½éœ€è¦ 2-5 åˆ†é’Ÿ

**åŸå› **: OpenVINO é¦–æ¬¡è¿è¡Œéœ€è¦ç¼–è¯‘æ¨¡å‹ä»¥é€‚é…ç¡¬ä»¶

**è§£å†³æ–¹æ¡ˆ**: 
- è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œè€å¿ƒç­‰å¾…
- ç¼–è¯‘åä¼šç¼“å­˜ï¼Œåç»­è¿è¡Œä¼šå¿«å¾ˆå¤š
- ç¼“å­˜ä½ç½®: `%LOCALAPPDATA%\openvino\cache`

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ INT4 é‡åŒ–æ¨¡å‹

INT4 æ¨¡å‹æ¯” FP16 å° 4 å€ï¼Œé€Ÿåº¦å¿« 2-3 å€ï¼š
```cmd
# æ¨èä½¿ç”¨ INT4
python deploy_qwen3_npu.py  # é»˜è®¤ä½¿ç”¨ INT4

# è€Œé FP16
# optimum-cli export openvino --weight-format fp16 ...
```

### 2. é€‰æ‹©åˆé€‚çš„è®¾å¤‡

```python
# æ€§èƒ½æ’åºï¼ˆä»å¿«åˆ°æ…¢ï¼‰
"NPU"           # æœ€å¿«ï¼Œæœ€çœç”µï¼ˆæ¨èï¼‰
"GPU"           # å¿«ï¼Œæ˜¾å­˜å ç”¨é«˜
"CPU"           # æ…¢ï¼Œå…¼å®¹æ€§æœ€å¥½
"AUTO"          # è‡ªåŠ¨é€‰æ‹©
```

### 3. è°ƒæ•´ç”Ÿæˆå‚æ•°

```python
# å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
response = pipe.generate(
    prompt,
    max_length=200,        # å‡å°‘é•¿åº¦æå‡é€Ÿåº¦
    temperature=0.7,       # é™ä½éšæœºæ€§
    do_sample=False        # ç¦ç”¨é‡‡æ ·ï¼ˆè´ªå©ªè§£ç ï¼‰
)
```

### 4. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¤šä¸ªè¯·æ±‚æ›´é«˜æ•ˆ
prompts = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
for prompt in prompts:
    response = pipe.generate(prompt)
```

---

## ğŸ“š æ›´å¤šèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [OpenVINO æ–‡æ¡£](https://docs.openvino.ai/)
- [OpenVINO GenAI æ–‡æ¡£](https://docs.openvino.ai/2025/openvino-workflow-generative/inference-with-genai.html)
- [Intel NPU æ–‡æ¡£](https://docs.openvino.ai/2025/openvino-workflow-generative/inference-with-genai/inference-with-genai-on-npu.html)

### æ¨¡å‹èµ„æº
- [Qwen å®˜æ–¹ä»“åº“](https://github.com/QwenLM/Qwen)
- [ModelScope æ¨¡å‹åº“](https://www.modelscope.cn/)
- [HuggingFace æ¨¡å‹åº“](https://huggingface.co/)

### é©±åŠ¨ä¸‹è½½
- [Intel Arc é©±åŠ¨](https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html)
- [Intel é©±åŠ¨ä¸­å¿ƒ](https://www.intel.com/content/www/us/en/download-center/home.html)

---

## ğŸ’¬ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ–‡æ¡£**: å…ˆæŸ¥çœ‹æœ¬æ–‡æ¡£å’Œé¡¹ç›® README
2. **æœç´¢ Issues**: åœ¨ GitHub Issues ä¸­æœç´¢ç±»ä¼¼é—®é¢˜
3. **æäº¤ Issue**: å¦‚æœé—®é¢˜æœªè§£å†³ï¼Œæäº¤æ–°çš„ Issueï¼ŒåŒ…å«ï¼š
   - é”™è¯¯ä¿¡æ¯ï¼ˆå®Œæ•´çš„é”™è¯¯å †æ ˆï¼‰
   - ç³»ç»Ÿä¿¡æ¯ï¼ˆWindows ç‰ˆæœ¬ã€Python ç‰ˆæœ¬ã€GPU å‹å·ï¼‰
   - å¤ç°æ­¥éª¤
4. **ç¤¾åŒºè®¨è®º**: å‚ä¸ GitHub Discussions

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€
